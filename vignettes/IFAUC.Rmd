---
title: Derivation of the Influence Function for AUC for competing risk data and survival
  data
author: "Johan Sebastian Ohlendorff & Thomas Alexander Gerds"
date: '2022-01-09'
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
header-includes: \usepackage{graphicx, verbatim, fancyvrb, setspace, xspace, colortbl, longtable, amsmath, caption, xfrac, float, mathabx,bbm,algorithm2e}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newcommand{\Xj}{\ensuremath{X^{\prime}}}
\newcommand{\xj}{\ensuremath{x^{\prime}}}
\newcommand{\AUC}{\ensuremath{\operatorname{AUC}}}
\newcommand{\Brier}{\ensuremath{\operatorname{Brier}}}
\newcommand{\survtau}{\ensuremath{\tilde S(\tau)}}
\newcommand{\hatsurvtau}{\ensuremath{\hat{\tilde{S}}(\tau)}}
\newcommand{\Htau}{\ensuremath{H(\tau)}}
\newcommand{\hatHtau}{\ensuremath{\hat H^{(i)}(\tau)}}

\newcommand{\Utau}{\ensuremath{U(\tau)}}
\newcommand{\hatUtau}{\ensuremath{\hat U^{(i)}(\tau)}}
\newcommand{\Vtau}{\ensuremath{V(\tau)}}
\newcommand{\hatVtau}{\ensuremath{\hat V^{(i)}(\tau)}}
\newcommand{\Wtau}{\ensuremath{W(\tau)}}
\newcommand{\hatWtau}{\ensuremath{\hat W^{(i)}(\tau)}}
\newcommand{\margprob}{\ensuremath{F}}
\newcommand{\hatmargprob}{\ensuremath{\hat{F}}}
\newcommand{\Zi}{\ensuremath{Z_i}}
\newcommand{\emp}{\ensuremath{I\negthickspace P_n}}
\newcommand{\ifauc}{\ensuremath{\mathrm{IF}_{\mathrm{AUC}}}}
\newcommand{\ifconsauc}{\ensuremath{\mathrm{IF}_{G \mathrm{\  known}, \mathrm{AUC}}}}
\newcommand{\hatifauc}{\ensuremath{\mathrm{\widehat{IF}}_{\mathrm{AUC}}}}
\newcommand{\ifnu}{\ensuremath{\mathrm{IF}_{\nu}}}
\newcommand{\ifnuc}{\ensuremath{\mathrm{IF}^1_{\nu}}}
\newcommand{\hatifnu}{\ensuremath{\mathrm{\widehat{IF}}_{\nu}}}
\newcommand{\hatifnuc}{\ensuremath{\mathrm{\widehat{IF}}^1_{\nu}}}
\newcommand{\ifmu}{\ensuremath{\mathrm{IF}_{\mu}}}
\newcommand{\hatifmu}{\ensuremath{\mathrm{\widehat{IF}}_{\mu}}}
\newcommand{\ifmuc}{\ensuremath{\mathrm{IF}^1_{\mu}}}
\newcommand{\hatifmuc}{\ensuremath{\mathrm{\widehat{IF}}^1_{\mu}}}

<!-- for use with Rikkes paper -->
\newcommand{\AUCO}{\hat{\theta}^{(1,1)}_{\tau,m}}
\newcommand{\AUCObin}{\ensuremath{\hat{\theta}^{(1,1)}_{m}}}
\newcommand{\auc}{\widehat{\text{auc}}}
\newcommand{\aucO}{\theta_{\tau,m}}
\newcommand{\D}{\mathrm{d}}
\newcommand{\Db}{D^*_{m,b}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\G}{\hat G_n}
\newcommand{\g}{\hat{\mathbb{G}}}
\newcommand{\II}{\mathcal{I}}
\newcommand{\I}[1]{\II_{\{#1\}}}
\newcommand{\Ibi}{\I{N_i^b=0}}
\newcommand{\Ibj}{\I{N_j^b=0}}
\newcommand{\Ibk}{\I{N_k^b=0}}
\newcommand{\IC}{\text{IF}}
\newcommand{\Isi}{\I{N_i=0}}
\newcommand{\LL}{\{\I{\T_{m+1}\leq \tau}-\R(Z_{m+1})\}^2}
\newcommand{\Lbi}{\{\I{\T_i\leq \tau}-\Rb(Z_i)\}^2}
\newcommand{\Li}{\{\I{\T_i\leq \tau}-\R(Z_i)\}^2}
\newcommand{\Lj}{\{\I{\T_j\leq \tau}-\R(Z_j)\}^2}
\newcommand{\loo}{leave-one-out bootstrap }
\newcommand{\lpo}{leave-pair-out bootstrap }
\newcommand{\Lt}{\ensuremath{L_t}}
\newcommand{\M}{\ensuremath{\omega_{\tau,m}}}
\newcommand{\m}{\hat{\omega}^{(1)}_{\tau,m}}
\newcommand{\mbin}{\hat{\omega}^{(1)}_{m}}
\newcommand{\MU}{\ensuremath{\hat{\mu}^{(1)}_{\tau,m}}}
\newcommand{\p}{\ensuremath{\P_n}}
\newcommand{\PSI}{\ensuremath{\hat{\psi}^{(1)}_{m}}}
\renewcommand{\P}{\ensuremath{\mathrm{P}}}
\newcommand{\PEK}{\ensuremath{P_{\epsilon,k}}}
\newcommand{\Qej}{\ensuremath{Q_{n,\epsilon,j}}}
\newcommand{\RR}{\ensuremath{R_{\tau}}}
\newcommand{\R}{\ensuremath{\RR(D_m)}}
\newcommand{\Rb}{\ensuremath{\RR(D_{m,b}^*)}}
\newcommand{\Rbi}{\ensuremath{R(D_{m,b}^*)}}
\newcommand{\T}{\ensuremath{\tilde{T}}}
\newcommand{\V}{\text{Var}}
\newcommand{\X}{\ensuremath{\tilde{X}}}
\newcommand{\XX}{X}
\newcommand{\W}{W_\tau}
\newcommand{\Wi}{\W(X_i,\hat G_n)}
\newcommand{\Wk}{\W(X_k,\hat G_n)}
\newcommand{\WWi}{\mathcal{W}_{T_i}(Z_i)}
\newcommand{\WWj}{\mathcal{W}_t(Z_j)}
\newcommand{\indep}{\perp \!\!\! \perp}

## Introduction 

In this document, we consider the estimation of the (possibly time-dependent) AUC. Let $R(D_m)(X)$ be a (risk) prediction for $X$ for a model $R$ trained on a data set $D_m$ of size $m$. Then, for binary data $Z=(Y,X)$ and $Z'=(Y',X')$ with $Z \indep Z'$, the AUC score is defined as:
$$
\text{AUC}_{R, D_m} = P(R(D_m)(X) > R(D_m)(X') | Y=1, Y' = 0) = \frac{\int \int I(R(D_m)(x) > R(D_m)(x'), y=1,y'=0)P(dz')P(dz)}{P(Y=1)P(Y'=0)}
$$
Note that in the above definition that $D_m$ is fixed, so the AUC above will depend on which data set that the model is trained on. To describe the situation with competing risks (and also survival), we introduce a random variable \(D\in\{1,2\}\) which indicates the cause (i.e., type
of the event) observed at time \(T\) such that \(D=1\) means that the
event of interest occurred, and \(D=2\) that a competing risk
occurred. We let \(Q\) denote the joint
probability measure of the uncensored data, \((T,D,X)\sim Q\), and $P$
the joint probability measure of the right censored data
$O=(\tilde{T},\Delta,X) \sim P$ now with $\Delta=D 1_{\{T \leq C\}}$
taking values in the set \(\{0,1,2\}\). Also let $G$ denote the survival function for the censoring distribution. Now for event type data $Z=(T,D,X)$ and $Z'=(T',D',X')$ with $Z \indep Z'$, we consider the above as a time-dependent discrimination measure for some fixed $\tau$:
$$
\begin{aligned}
\text{AUC}_{R, D_m, \tau} &= Q(R(D_m)(X) > R(D_m)(X') | T\leq \tau, D=1,(T' > \tau \cup D'=2)) \\
  &= \frac{Q(R(D_m)(X) > R(D_m)(X'), T\leq \tau, D=1,(T' > \tau \cup D'=2))}{Q(T\leq \tau, D=1,(T' > \tau \cup D'=2))}\\
  &= \frac{\nu_\tau(Q)}{\mu_\tau(Q)}
\end{aligned}
$$
with
$$
\begin{aligned}
\nu_\tau(Q)&= \iint 1_{\{R(D_m)(x) > R(D_m)(x'), t \leqslant \tau,  t^{\prime}>\tau,d=1\}} \frac{P(dz)}{G(t- | x)} \frac{P(dz')}{G\left(\tau | x' \right)} \\
&+ \iint 1_{\{R(D_m)(x) > R(D_m)(x'), t \leqslant \tau,  t^{\prime}\leq\tau,d=1, d' = 2\}} \frac{P(dz)}{G(t- | x)} \frac{P(dz')}{G\left(t'- | x' \right)}
\end{aligned}
$$
and
$$
\mu_\tau(Q)= \iint 1_{\{t \leqslant \tau,  t^{\prime}>\tau,d=1\}} \frac{P(dz)}{G(t- | x)} \frac{P(dz')}{G\left(\tau | x' \right)} + \iint 1_{\{t \leqslant \tau,  t^{\prime}\leq\tau,d=1, d' = 2\}} \frac{P(dz)}{G(t- | x)} \frac{P(dz')}{G\left(t'- | x' \right)}
$$

When there are no competing risks, the definition of the above is the same as for binary data with $Y=I(T \leq \tau)$ and $Y'=I(T' > \tau)$. Here we used IPCW to rewrite the above, such that we can actually estimate it from observed data. It is straightforward to write down these plugin-in estimators. 

In the situation with cross-validation, it will be of interest to estimate $\mathbb{E}_{D_m}[\text{AUC}_{R, D_m}]$ or $\mathbb{E}_{D_m}[\text{AUC}_{R, D_m, \tau}]$, i.e. the expected performance of the model over all training data sets of size $m$. 

In the below sections, we will suggest some estimators of the AUC and their asymptotic variances (by using influence functions). Also, we will calculate the efficient influence function for the AUC.

##  Efficient influence function with known censoring
We will only cover the competing risk case with uncensored data (or more generally with known censoring distribution), as the efficient influence function for AUC for binary data and survival data follow from this. To derive the Gateaux derivative of the functional at $\text{AUC}_{R, D_m, \tau}$ in the
direction of an observation $(T_i,D_i,X_i)$ we introduce the corresponding
path,
\begin{align*}
Q_{\varepsilon}^{i}=Q+\varepsilon\left\{\delta_{\left\{T_{i}, D_i,
      X_i\right\}}-Q\right\}.
\intertext{and the following short notation
$\partial_{\varepsilon}=\left.\frac{\partial}{\partial
  \varepsilon}\right|_{\varepsilon=0}$ to obtain the directional derivative:}
 \partial_{\varepsilon} Q_{\varepsilon}^{i}=\delta_{\left\{T_{i}, D_i, X_i\right\}}-Q.
\end{align*}
The Gateaux derivative of the functional $\text{AUC}_{R, D_m, \tau}$ is obtained
using straight-forward calculus:
\begin{equation*}
	\ifconsauc(Z_i,\tau)=\frac{\ifnu(\Zi;\tau)  \mu_{\tau}(Q) - \nu_{\tau}(Q)  \ifmu(\Zi;\tau)} {\mu_{\tau}(Q)^2}
\end{equation*}
where
\begin{align*}
	\ifnu(\Zi;\tau) &= \frac{1_{\{\tilde{T}_i \leqslant \tau, D_i = 1\}}}{G(\tilde{T_i}- | X_i)}\int 1_{\{R(D_m)(X_i) > R(D_m)(x')\}}  \left(1_{\{t^{\prime}>\tau\}} \frac{1}{G(\tau | x')}+  1_{\{t^{\prime} \leqslant \tau, d' = 2\}}  \frac{1}{G(t'- | x')}\right) P(dz') \\
	&+ \left(\frac{1_{ \{ \tilde{T_i} \leq \tau, D_i = 2\}} }{G(\tilde{T_i} - | X_i)} +  \frac{1_{ \{ \tilde{T_i} > \tau \}} }{G(\tau | X_i )}\right) \int  1_{\{R(D_m)(x) > R(D_m)(X_i),t \leqslant \tau, d= 1\}}  \frac{P(dz)}{G(t- | x)}
\end{align*}
and
\begin{align*}
	\ifmu(\Zi;\tau) &= \frac{1_{\{\tilde{T}_i \leqslant \tau, D_i = 1\}}}{G(\tilde{T_i}- | X_i)}\int   \left(1_{\{t^{\prime}>\tau\}} \frac{1}{G(\tau | x')}+  1_{\{t^{\prime} \leqslant \tau, d' = 2\}}  \frac{1}{G(t'- | x')}\right) P(dz') \\
	&+ \left(\frac{1_{ \{ \tilde{T_i} \leq \tau, D_i = 2\}} }{G(\tilde{T_i} - | X_i)} +  \frac{1_{ \{ \tilde{T_i} > \tau \}} }{G(\tau | X_i )}\right) \int 1_{\{t \leqslant \tau, d= 1\}}  \frac{P(dz)}{G(t- | x)}
\end{align*}

## Efficient influence function 
Similar to the case from before, we can obtain the efficient influence function when the censoring is unknown and has to be estimated. We need the influence function for the censoring as part of these calculations:
\begin{align*}
\kappa_{t,x}(P_{\varepsilon}^i) &= \exp(-\int_0^t \frac{dP_{\varepsilon}(s,0|x)}{P_\varepsilon(\tilde{T} > s|X=x)}) \\
\partial_{\varepsilon} P_{\varepsilon}(\tilde{T} >s , X=x) &= \mathbbm{1}_{\{\tilde{T}_i > s, X_i = x\}}-P(\tilde{T} > s, X = x) \\
\partial_{\varepsilon} P_{\varepsilon}(\tilde{T} \leq s, \Delta=0, X=x) &= \mathbbm{1}_{\{\tilde{T}_i \leq s,\Delta_i=0, X_i = x\}}-P(\tilde{T} \leq s, \Delta=0, X = x)
\end{align*}
Let $f_i(t,x) = \partial_{\varepsilon} \left[\int_0^t \frac{dP_{\varepsilon}(s,0|x)}{P_\varepsilon(\tilde{T} > s|X=x)}\right]$, so that $f_i(t,x)$ is the influence function of the cumulative hazard (conditioned on $x$) of the censoring. We observe that 
$$
f_i(t,x) = \frac{\mathbbm{1}_{\{\tilde{T_i} \leq t, \Delta_i = 0\}} \delta_{X_i}(x)}{G(\tilde{T_i}| X_i)S(\tilde{T_i}|X_i)} -\int_0^{\tilde{T}_i \wedge t} \frac{ \delta_{X_i}(x)dP(s,0 | x)}{G(s|X_i)^2S(s|X_i)^2}
$$
Here $\delta$ denotes the Dirac measure.  When $X$ is discrete, $\delta_{X_i}(x)$ is to be understood as $\frac{I(X_i=x)}{P(X_i=x)}$. With this in mind, we find that
\begin{equation*}
	\ifauc(Z_i,\tau)=\ifconsauc(Z_i,\tau)+	\ifauc(Z_i,\tau)_\text{cens}
\end{equation*}
where 
$$
\ifauc(Z_i,\tau)_\text{cens} = \frac{\ifnu(\Zi;\tau)_\text{cens}  \mu_{\tau}(Q) - \nu_{\tau}(Q)  \ifmu(\Zi;\tau)_\text{cens}} {\mu_{\tau}(Q)^2}
$$
and
\begin{align*}
	\ifnu(\Zi;\tau)_{\text{cens}} &=\iint  1_{\{R(D_m)(x) > R(D_m)(x')\}}\left(1_{\{t^{\prime}>\tau\}} \frac{1}{G(\tau | x')}+  1_{\{t^{\prime} \leqslant \tau, d' = 2\}}  \frac{1}{G(t'- | x')}\right) P(dz')  1_{\{t \leqslant \tau, d = 1\}} \frac{f_i(t-,x   )P(dz)}{G(t- | x)}  \\
	&+ \iint   1_{\{R(D_m)(x) > R(D_m)(x'), t \leqslant \tau, d = 1\}}  \frac{P(dz)}{G(t- | x)} \left( \frac{1_{\{t^{\prime}>\tau\}} f_i(\tau,x')}{G(\tau | x')} + 1_{\{t^{\prime} \leqslant \tau, d'=2\}}f_i(t'-,x') \frac{1}{G(t'- | x')} \right)P(dz')
\end{align*}
and
\begin{align*}
	\ifmu(\Zi;\tau)_{\text{cens}} &=\int \left(1_{\{t^{\prime}>\tau\}} \frac{1}{G(\tau | x')}+  1_{\{t^{\prime} \leqslant \tau, d' = 2\}}  \frac{1}{G(t'- | x')}\right) P(dz') \int 1_{\{t \leqslant \tau, d = 1\}} \frac{f_i(t-,x   )P(dz)}{G(t- | x)}  \\
	&+ \int  1_{\{t \leqslant \tau, d = 1\}}  \frac{P(dz)}{G(t- | x)} \int \left( \frac{1_{\{t^{\prime}>\tau\}} f_i(\tau,x')}{G(\tau | x')} + 1_{\{t^{\prime} \leqslant \tau, d' = 2\}}f_i(t'-,x') \frac{1}{G(t'- | x')} \right)P(dz')
\end{align*}

### Notes on the case with covariates
- Some of the censoring may be evaluated by noting the following
$$
\scriptstyle
\int_X \int_0^\tau 1_{\{d =k\}}H(x)f_i(t-,x) \frac{P(dz)}{G(t-|x)} = H(X_i)\left(\frac{I(\tilde{T}_i \leq \tau, \Delta_i = 0)}{G(\tilde{T}_i|X_i)S(\tilde{T}_i|X_i)}(F_k(\tau|X_i)-F_k(\tilde{T}_i|X_i))-\int_0^{\tilde{T}_i \wedge \tau} \frac{(F_k(\tau|X_i)-F_k(s|X_i))}{G(s|X_i)^2S(s|X_i)^2}P(ds,0|X_i)\right)
$$
where $H$ is an arbitrary function of $x$ (but not $t$!), $k \in \{1,2\}$ and $F_k$ is the subdistribution function for cause $k$.
- For Term (3) (and similarly (10)), we can use that  
$$
\begin{aligned}
\scriptstyle
\int_ X\int H(x')  1_{\{t' > \tau\}} f_i(\tau, x')\frac{P(dz')}{G(\tau | x')}&=\frac{H(X_i)}{G(\tau | X_i)} P(\tilde{T} > \tau | X_i)\left(\frac{I(\tilde{T}_i \leq \tau, \Delta_i = 0)}{G(\tilde{T}_i|X_i)S(\tilde{T}_i|X_i)}-\int_0^{\tilde{T}_i \wedge \tau} \frac{1}{G(s|X_i)^2S(s|X_i)^2}P(ds,0|X_i)\right) \\
&=H(X_i) S(\tau | X_i)\left(\frac{I(\tilde{T}_i \leq \tau, \Delta_i = 0)}{G(\tilde{T}_i|X_i)S(\tilde{T}_i|X_i)}-\int_0^{\tilde{T}_i \wedge \tau} \frac{1}{G(s|X_i)^2S(s|X_i)^2}P(ds,0|X_i)\right) \\
\end{aligned}
$$
where $H$ is again an arbitrary function.

## Estimation 
We can estimate the AUC by using the plugin-estimator $\mathbb{P}_n$ instead of $P$. We also need to estimate the censoring distribution, typically either by a Cox model $\hat{G}_\text{cox}$ or a Kaplan-Meier model $\hat{G}_\text{KM}$, or maybe some other model. The influence function for the first two estimators is fairly easy to estimate (the functional delta theorem will yield that the influence function for these estimators is pretty much the same as the efficient influence function, except $f_i(t,z)$ being given in a slightly different way). In fact, one can fairly easily implement $\hat{f}_i(t,z)$ for these models, so that the influence function of these estimators can be estimated. However, this is generally not so for other types of estimators, and for these estimators, we will drop the censoring term, leading to conservative confidence interval, i.e. assume that $\ifauc(Z_i,\tau)_\text{cens}  = 0$.

In any case, we can actually estimate the terms in the influence function very (computationally) efficiently that do not involve the censoring by sorting the risk predictions. 

For some ideas of how to implement the estimation of the censoring terms when we have Kaplan-Meier censoring, see **IFKMCens.pdf**.

## Cross-validation

### Binary case
Our cross-validation algorithm repeatedly splits the dataset \(D_n\) of size $n$
into training and validation datasets as follows. Let \(B\) be a large
integer. For each \(b=1,\ldots,B\) we draw a bootstrap dataset
\(\Db=\{X_{b,1}^*,\ldots,X_{b,m}^*\}\) of size \(m\) with
replacement from the data \(D_n\). For \(i=1,\ldots,n\) let \(N_i^b\) be
the number of times subject \(i\) is included in \(\Db\). In step
\(b\) of the cross-validation algorithm the bootstrap dataset \(\Db\)
is used for training. We apply \(R \) to \(\Db\) to obtain the
prediction model \(\Rbi\). All subjects \(i\) for which \(N_i^b=0\) are
out-of-bag and we let these subjects form the validation dataset of step \(b\). First let us construct the influence function in this case with binary data, $X=(Y,Z)$. In this case, we consider estimation of the functional (i.e. the definition of the AUC in cross-validation)

In this section we extend the ideas from the previous
section and define a \lpo IPCW estimator of AUC.
The AUC can be written as
\begin{align*}
  \text{AUC}(D_m)&=\E_{X_{m+1},X_{m+2}}\Big[\I{\RR(D_m)(Z_{m+1})>\RR(D_m)(Z_{m+2})}\big\vert Y_{m+1} = 1, Y_{m+2} = 0, D_m\Big] \\
  &=\frac{\E_{X_{m+1},X_{m+2}}\Big[\I{\R(Z_{m+1})>\R(Z_{m+2})} \I{Y_{m+1} = 1}\I{Y_{m+2} = 0}\big\vert D_m\Big]}
  {\E_{X_{m+1}}\Big[\I{Y_{m+1} = 1}\Big]\E_{X_{m+2}}\Big[\I{Y_{m+2} = 0}\Big]} 
\end{align*}
With the notation 
\begin{equation*}
  \Theta_{m}(Z_{m+1},Z_{m+2})=\E_{D_m}\big[\I{\R(Z_{m+1})>\R(Z_{m+2})}\big\vert Z_{m+1},Z_{m+2}\big],
\end{equation*}
the expected parameter \(\theta_{m} =\E_{D_n}\big[\text{AUC}(D_n)\big] \) can then be written as 
\begin{align}
  \theta_{m} &=\E_{D_m}\left[\frac{\E_{X_{m+1},X_{m+2}}\Big[\I{\R(Z_{m+1})>\R(Z_{m+2})} \I{Y_{m+1} = 1}\I{Y_{m+2} = 0}\big\vert D_m\Big]}
  {\E_{X_{m+1}}\Big[\I{Y_{m+1} = 1}\Big]\E_{X_{m+2}}\Big[\I{Y_{m+2} = 0}\Big]}\right]\nonumber\\
  &=\frac{\E_{X_{m+1},X_{m+2}}\left[\Theta_{m}(Z_{m+1},Z_{m+2})\I{Y_{m+1} = 1}\I{Y_{m+2} = 0}\right]}
  {\E_{X_{m+1}}\Big[\I{Y_{m+1} = 1}\Big]\E_{X_{m+2}}\Big[\I{Y_{m+2} = 0}\Big]}=\frac{\mathcal{A}_{\tau,m}}{\mathcal{B}_{\tau}}
\end{align}

As before, let \(\Db\) be a bootstrap sample drawn with replacement
from \(D_m\), and let \(\Rbi\) be a prediction modeling algorithm trained in
\(\Db\). The idea of the \lpo estimator is to evaluate the concordance
of predicted risks obtained from \(\Rbi\) for all pairs of subjects
\((i,j)\) for which both subject \(i\) and subject \(j\) is out-of-bag   
\begin{equation*}
  \I{\Rbi(Z_i)>\Rbi(Z_j)}\Ibi\Ibj
\end{equation*}  
The contribution of pair \((i,j)\) to the \lpo estimator is the average
concordance over all bootstrap samples for which both \(i\) and \(j\) are
out-of-bag 
\begin{equation}
\label{eq:lpo}
  \hat{\Theta}^{(1,1)}_{m}(Z_{i},Z_{j})=\frac{\sum_{b=1}^{B}\I{\Rbi(Z_{i})>\Rbi(Z_{j})}\Ibi\Ibj}{\sum_{b=1}^{B}\Ibi\Ibj}
\end{equation}
In the case of no censoring, the \lpo estimate of \(\aucO\) is obtained
by inserting \(\hat{\Theta}^{(1,1)}_{m}\) in
$\theta_m$ and replacing the expectations by empirical means 
\begin{equation*}
  \frac{1}{n^2}\frac{1}{\hat{\mathcal{B}}}\sum_{i=1}^n\sum_{j=1}^n\hat{\Theta}^{(1,1)}_{m}(Z_{i},Z_{j})\I{Y_i=1}\I{Y_j=0},
\end{equation*}
with
\(\hat{\mathcal{B}}=n^{-2}\big[\sum_{i=1}^n\I{Y_i=1}\big]\big[\sum_{j=1}^n\I{Y_j=0}\big]\).

### Influence function (generally)
We note that we may actually use our results from the test-train section on any functional, $\phi(D_m)_\tau$ defined in the test-train situation. Then the influence function of the function  $\Phi_\tau := \mathbb{E}_{D_m} [\phi(D_m)_\tau]$ (with $\tau$ removed from the notation if we are in the binary sitaution) from the test-train situation as follows by finding the Gateaux derivative for observation $i$

$$
\int \cdots \int \text{IC}_{\phi(D_m)_\tau}^i P(dx_1) \cdots P(dx_m) + \sum_{j=1}^m  \int \cdots \int \phi(D_m)_\tau \delta_{x_j}(x_k) \prod_{i \neq j} P(dx_i) - m \Phi_\tau 
$$

Then using that approximately, we have that 
$$
\int \cdots \int \phi(D_m)_\tau \delta_{x_j}(x_k) \prod_{i \neq j} P(dx_i) \approx  \int \cdots \int \phi(D_m)_\tau P(dx_j)\prod_{i \neq j} P(dx_i) := \Phi_\tau 
$$
i.e. we use the expected value as an approximation of the actual value (this is ok assuming that the variance of the LHS is not too large), so we have the Gateux derivative 

$$
\int \cdots \int \text{IC}_{\phi(D_m)_\tau}^i P(dx_1) \cdots P(dx_m)
$$

and we know $$\text{IC}_{\phi(D_m)_\tau}^i$$ from the train-test situation.  Thus, by interchanging the integrals, we get after some calculations, 
\begin{align*}
  &\IC_{\nu}(m;x_k)=\frac{1}{\eta(\P)}\Big[\int\Theta_{m}(z_{m+1},z_k)\I{y_{k}=1,y_{m+2}=0}\P(\D x_{m+1})\\
  &\hspace{3cm}+\int\Theta_{m}(z_k,z_{m+2})\I{y_{m+1}=1,y_{k}=0}\P(\D x_{m+2})\Big]\\
  &-\frac{\nu_{m}(\P)}{\eta(\P)}\Big[\I{y_k=1}\Big]
  \Big[\int \I{y_{m+2}=0}\P(\D x_{m+2})\Big]\\
  &-\frac{\nu_{n}(\P)}{\eta(\P)}\Big[\int \I{y_{m+1}=1}\P(\D x_{m+1})\Big]
  \Big[\I{y_k=0}\Big]
\end{align*}

### Estimating the Influence function
We suggest to estimate the influence function by
\begin{align*}
  &\hat{\IC}_{\nu}(\tau,m;X_k)=\frac{1}{n}\frac{1}{\hat{\mathcal{B}}} \Bigg[\sum_{i=1}^n\hat{\Theta}^{(1,1)}_{m}(Z_i,Z_k)\I{Y_i=1,Y_k= 0}
  +\sum_{j=1}^n\hat{\Theta}^{(1,1)}_{m}(Z_k,Z_j)\I{Y_k=1,Y_j = 0} \Bigg]\\
      &-\frac{\AUCObin}{\hat{\mathcal{B}}} \Bigg[\I{Y_k = 1}\Bigg]
  \Bigg[\frac{1}{n}\sum_{j=1}^n \I{Y_j = 0}\Bigg]\\
  &-\frac{\AUCObin}{\hat{\mathcal{B}}_{\tau}}\Bigg[\frac{1}{n}\sum_{i=1}^n \I{Y_i = 1} \Bigg]
  \Bigg[\I{Y_k = 0}\Bigg]
\end{align*}

## Survival and Competing risk cases
The idea is the same as before. Let $\nu^{1}_{\tau,m}(P)$ be the numerator of the cross-validated AUC. Then, for the most general case (competing risk case), we get that 
\begin{align*}
\frac{\ifnu(\Zi;\tau,m)\mu_\tau(P) - \nu^{1}_{\tau,m}(P) \ifmu(\Zi;\tau)}{\mu_\tau(P)^2 }
\end{align*}
Note that $\mu_{\tau}(P)$ is defined precisely as before (and also $\ifmu$ is the same, because they are constants in terms of $(x_1,...,x_m)$), but we must redefine $\ifnu$, so
\begin{align}
	\ifnu(\Zi;\tau,m) &= \frac{1_{\{\tilde{T}_i \leqslant \tau, \Delta_i = 1\}}}{G(\tilde{T_i}- | Z_i)}\int  \Theta_m(X_i,x') \left(1_{\{t^{\prime}>\tau\}} \frac{1}{G(\tau | z')}+  1_{\{t^{\prime} \leqslant \tau\}}  \frac{\I{\delta'=2}}{G(t'- | z')}\right) P(dx') \\
	&+\iint  \Theta_m(x,x') \left(1_{\{t^{\prime}>\tau\}} \frac{1}{G(\tau | z')}+  1_{\{t^{\prime} \leqslant \tau\}}  \frac{\I{\delta'=2}}{G(t'- | z')}\right) P(dx')  1_{\{t \leqslant \tau\}} \frac{f_i(t-,z   )P(dx) \I{\delta=1}}{G(t- | z)}  \\
	&+ \iint  \Theta_m(x,x')  1_{\{t \leqslant \tau\}}  \frac{P(dx) \I{\delta=1}}{G(t- | z)} \left( \frac{1_{\{t^{\prime}>\tau\}} f_i(\tau,z')}{G(\tau | z')} + 1_{\{t^{\prime} \leqslant \tau\}}f_i(t'-,z') \frac{\I{\delta'=2}}{G(t'- | z')} \right)P(dx')\\
	&+ \left(\frac{1_{ \{ \tilde{T_i} \leq \tau, \Delta_i = 2\}} }{G(\tilde{T_i} - | Z_i)} +  \frac{1_{ \{ \tilde{T_i} > \tau \}} }{G(\tau | Z_i )}\right) \int \Theta_m(x,X_i )1_{\{t \leqslant \tau\}}  \frac{P(dx) \I{\delta=1}}{G(t- | x)}
\end{align}
Similarly for the denominator, we need to do this, so
\begin{align}
	\ifmu(\Zi;\tau) &= \frac{1_{\{\tilde{T}_i \leqslant \tau, \Delta_i = 1\}}}{G(\tilde{T_i}- | Z_i)}\int   \left(1_{\{t^{\prime}>\tau\}} \frac{1}{G(\tau | z')}+  1_{\{t^{\prime} \leqslant \tau\}}  \frac{\I{\delta'=2}}{G(t'- | z')}\right) P(dx') \\
	&+\int \left(1_{\{t^{\prime}>\tau\}} \frac{1}{G(\tau | z')}+  1_{\{t^{\prime} \leqslant \tau\}}  \frac{\I{\delta'=2}}{G(t'- | z')}\right) P(dx') \int 1_{\{t \leqslant \tau\}} \frac{f_i(t-,z   )P(dx) \I{\delta=1}}{G(t- | z)}  \\
	&+ \int  1_{\{t \leqslant \tau\}}  \frac{P(dx) \I{\delta=1}}{G(t- | z)} \int \left( \frac{1_{\{t^{\prime}>\tau\}} f_i(\tau,z')}{G(\tau | z')} + 1_{\{t^{\prime} \leqslant \tau\}}f_i(t'-,z') \frac{\I{\delta'=2}}{G(t'- | z')} \right)P(dx')\\
	&+ \left(\frac{1_{ \{ \tilde{T_i} \leq \tau, \Delta_i = 2\}} }{G(\tilde{T_i} - | Z_i)} +  \frac{1_{ \{ \tilde{T_i} > \tau \}} }{G(\tau | Z_i )}\right) \int 1_{\{t \leqslant \tau\}}  \frac{P(dx) \I{\delta=1}}{G(t- | x)}
\end{align}
