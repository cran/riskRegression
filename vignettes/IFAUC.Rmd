---
title: Derivation of the Influence Function for AUC for competing risk data and survival
  data
author: "Johan Sebastian Ohlendorff & Thomas Alexander Gerds"
date: '2022-01-09'
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
header-includes: \usepackage{graphicx, verbatim, fancyvrb, setspace, xspace, colortbl, longtable, amsmath, caption, xfrac, float, mathabx,bbm,algorithm2e}

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newcommand{\Xj}{\ensuremath{X^{\prime}}}
\newcommand{\xj}{\ensuremath{x^{\prime}}}
\newcommand{\AUC}{\ensuremath{\operatorname{AUC}}}
\newcommand{\Brier}{\ensuremath{\operatorname{Brier}}}
\newcommand{\survtau}{\ensuremath{\tilde S(\tau)}}
\newcommand{\hatsurvtau}{\ensuremath{\hat{\tilde{S}}(\tau)}}
\newcommand{\Htau}{\ensuremath{H(\tau)}}
\newcommand{\hatHtau}{\ensuremath{\hat H^{(i)}(\tau)}}

\newcommand{\Utau}{\ensuremath{U(\tau)}}
\newcommand{\hatUtau}{\ensuremath{\hat U^{(i)}(\tau)}}
\newcommand{\Vtau}{\ensuremath{V(\tau)}}
\newcommand{\hatVtau}{\ensuremath{\hat V^{(i)}(\tau)}}
\newcommand{\Wtau}{\ensuremath{W(\tau)}}
\newcommand{\hatWtau}{\ensuremath{\hat W^{(i)}(\tau)}}
\newcommand{\margprob}{\ensuremath{F}}
\newcommand{\hatmargprob}{\ensuremath{\hat{F}}}
\newcommand{\Zi}{\ensuremath{Z_i}}
\newcommand{\emp}{\ensuremath{I\negthickspace P_n}}
\newcommand{\ifauc}{\ensuremath{\mathrm{IF}_{\mathrm{AUC}}}}
\newcommand{\hatifauc}{\ensuremath{\mathrm{\widehat{IF}}_{\mathrm{AUC}}}}
\newcommand{\ifnu}{\ensuremath{\mathrm{IF}_{\nu}}}
\newcommand{\ifnuc}{\ensuremath{\mathrm{IF}^1_{\nu}}}
\newcommand{\hatifnu}{\ensuremath{\mathrm{\widehat{IF}}_{\nu}}}
\newcommand{\hatifnuc}{\ensuremath{\mathrm{\widehat{IF}}^1_{\nu}}}
\newcommand{\ifmu}{\ensuremath{\mathrm{IF}_{\mu}}}
\newcommand{\hatifmu}{\ensuremath{\mathrm{\widehat{IF}}_{\mu}}}
\newcommand{\ifmuc}{\ensuremath{\mathrm{IF}^1_{\mu}}}
\newcommand{\hatifmuc}{\ensuremath{\mathrm{\widehat{IF}}^1_{\mu}}}

<!-- for use with Rikkes paper -->
\newcommand{\AUCO}{\hat{\theta}^{(1,1)}_{\tau,m}}
\newcommand{\AUCObin}{\ensuremath{\hat{\theta}^{(1,1)}_{m}}}
\newcommand{\auc}{\widehat{\text{auc}}}
\newcommand{\aucO}{\theta_{\tau,m}}
\newcommand{\D}{\mathrm{d}}
\newcommand{\Db}{D^*_{m,b}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\G}{\hat G_n}
\newcommand{\g}{\hat{\mathbb{G}}}
\newcommand{\II}{\mathcal{I}}
\newcommand{\I}[1]{\II_{\{#1\}}}
\newcommand{\Ibi}{\I{N_i^b=0}}
\newcommand{\Ibj}{\I{N_j^b=0}}
\newcommand{\Ibk}{\I{N_k^b=0}}
\newcommand{\IC}{\text{IF}}
\newcommand{\Isi}{\I{N_i=0}}
\newcommand{\LL}{\{\I{\T_{m+1}\leq \tau}-\R(Z_{m+1})\}^2}
\newcommand{\Lbi}{\{\I{\T_i\leq \tau}-\Rb(Z_i)\}^2}
\newcommand{\Li}{\{\I{\T_i\leq \tau}-\R(Z_i)\}^2}
\newcommand{\Lj}{\{\I{\T_j\leq \tau}-\R(Z_j)\}^2}
\newcommand{\loo}{leave-one-out bootstrap }
\newcommand{\lpo}{leave-pair-out bootstrap }
\newcommand{\Lt}{\ensuremath{L_t}}
\newcommand{\M}{\ensuremath{\omega_{\tau,m}}}
\newcommand{\m}{\hat{\omega}^{(1)}_{\tau,m}}
\newcommand{\mbin}{\hat{\omega}^{(1)}_{m}}
\newcommand{\MU}{\ensuremath{\hat{\mu}^{(1)}_{\tau,m}}}
\newcommand{\p}{\ensuremath{\P_n}}
\newcommand{\PSI}{\ensuremath{\hat{\psi}^{(1)}_{m}}}
\renewcommand{\P}{\ensuremath{\mathrm{P}}}
\newcommand{\PEK}{\ensuremath{P_{\epsilon,k}}}
\newcommand{\Qej}{\ensuremath{Q_{n,\epsilon,j}}}
\newcommand{\RR}{\ensuremath{R_{\tau}}}
\newcommand{\R}{\ensuremath{\RR(D_m)}}
\newcommand{\Rb}{\ensuremath{\RR(D_{m,b}^*)}}
\newcommand{\Rbi}{\ensuremath{R(D_{m,b}^*)}}
\newcommand{\T}{\ensuremath{\tilde{T}}}
\newcommand{\V}{\text{Var}}
\newcommand{\X}{\ensuremath{\tilde{X}}}
\newcommand{\XX}{X}
\newcommand{\W}{W_\tau}
\newcommand{\Wi}{\W(X_i,\hat G_n)}
\newcommand{\Wk}{\W(X_k,\hat G_n)}
\newcommand{\WWi}{\mathcal{W}_{T_i}(Z_i)}
\newcommand{\WWj}{\mathcal{W}_t(Z_j)}

## Introduction 

In this document we derive the influence function of the inverse
probability of censoring weighted (IPCW) estimator of the
time-dependent AUC in the cases with and without competing risks. We
denote the uncensored time to event by \(T\), the right censoring time
by \(C\), and by \(X\) a continuous marker. Let us first look at the case, where $T$ is not censored (and there is only one event).

##  Influence function uncensored case

In the uncensored case, we observe \((T,X)\) and denote \(Q\) for the
joint probability measure $Q$, i.e., $(T,X) \sim Q$.
The time-dependent AUC at
time \(\tau\) for marker \(X\)  is defined as:
$$
\AUC(\tau)=Q(X>\Xj | T \leq \tau, T^{\prime}>\tau)=\frac{Q(T \leq \tau,
  T^{\prime}>\tau, X>\Xj)}{Q(T \leq \tau,
  T^{\prime}>\tau)}
$$
Let \(\mathcal{Q}\) be the set of all probability measures of \(T,X\)
and consider the functional \(\nu_{\tau}:\mathcal{Q}\to [0,1]\)
$$
\nu_{\tau}(Q)=\int \int 1_{\{t \leq \tau, t^{\prime}>\tau, x>\xj\}} d Q(t, x) d Q (t^{\prime}, \xj)
$$
Note that the value of the functional is the numerator of the \AUC:
$$
\nu_{\tau}(Q)=Q(T \leq \tau, T^{\prime}>\tau, X>\Xj)
$$
To derive the Gateaux derivative of the functional at \(Q\) in the
direction of an observation \(T_i,X_i\) we introduce the corresponding
path,
\begin{align*}
Q_{\varepsilon}^{i}=Q+\varepsilon\left\{\delta_{\left\{T_{i},
      X_i\right\}}-Q\right\}.
\intertext{and the following short notation
$\partial_{\varepsilon}=\left.\frac{\partial}{\partial
  \varepsilon}\right|_{\varepsilon=0}$ to obtain the directional derivative:}
 \partial_{\varepsilon} Q_{\varepsilon}^{i}=\delta_{\left\{T_{i}, X_i\right\}}-Q.
\end{align*}
The Gateaux derivative of the functional \(\nu_{\tau}\) is obtained
using straight-forward calculus:
\begin{align*}
  \partial_{\varepsilon} \nu_{\tau}(Q_{\varepsilon})&=\int \int 1_{\{t \leq \tau, t^{\prime}>\tau, x>\xj\}} \partial_{\varepsilon} Q_{\varepsilon}^{i} (t,x) d Q (t^{\prime}, \xj)\\
                                                      &\quad + \int \int 1_{\{t \leq \tau, t^{\prime}>\tau, x>\xj\}} d Q(t, x) \partial_{\varepsilon} Q_{\varepsilon}^{i} (t^{\prime}, \xj) \\
&= \int \int 1_{\{t \leq \tau, t^{\prime}>\tau, x>\xj\}} d[\delta_{\left\{T_{i}, X_i\right\}}-Q] (t,x) d Q (t^{\prime}, \xj) \\
                                                      &\quad + \int \int 1_{\{t \leq \tau, t^{\prime}>\tau, x>\xj\}} d Q(t, x) d [\delta_{\left\{T_{i}, X_i\right\}}-Q](t^{\prime}, \xj) \\
&= \int_{-\infty}^\infty \int_{0}^{\tau} Q(T>\tau, X<x) d\left[\delta_{\left\{T_{i}, X_i\right\}}-Q\right](t,x)\\
                                                      &\quad +\int_{-\infty}^\infty \int_{\tau}^{\infty}  Q\left(T \leqslant \tau, X>\xj\right) d\left[\delta_{\left\{T_{i}, X_i\right\}}-Q\right](t',x')\\
&=1_{\left\{T_{i} \leqslant \tau\right\}} Q\left(T>\tau, X<X_{i}\right) +1_{\left\{T_{i}>\tau\right\}} Q\left(T \leqslant \tau, X>X_{i}\right)-2\nu_{\tau}(Q).
\end{align*}

Now we consider the functional \(\mu_{\tau}:\mathcal{Q}\to [0,1]\)
corresponding to the denominator of the \AUC:
$$
\mu_{\tau}(Q)=\int \int 1_{\{t \leq \tau, t^{\prime}>\tau\}} d Q(t, x) d Q (t^{\prime}, \xj)=Q(T \leq \tau, T' > \tau).
$$
An analogous calculation yields that
$$
\partial_{\varepsilon} \mu_{\tau}(Q_{\varepsilon}) = 1_{\left\{T_{i} \leqslant \tau\right\}} Q\left(T>\tau\right)+1_{\left\{T_{i}>\tau\right\}} Q\left(T \leqslant \tau\right)-2\mu_{\tau}(Q)
$$
The quotient rule now yields that the Gateaux
derivative for the functional
\(\AUC_{\tau}(Q)={\nu_{\tau}(Q)}/{\mu_{\tau}(Q)}\) is given by
\begin{align*}
 &IF_{\AUC}(T_i,X_i;\tau) =  (\mu_{\tau}(Q))^{-2}\\
                                             &\quad \left[1_{\left\{T_{i} \leqslant \tau\right\}} (Q\left(T>\tau, X<X_{i}\right)\mu_{\tau}(Q)-Q(T > \tau) \nu_{\tau}(Q))\right.\\
  &\quad \left. +1_{\left\{T_{i}>\tau\right\}} (Q\left(T \leqslant \tau, X>X_{i}\right)\mu_{\tau}(Q) - \nu_{\tau}(Q)Q(T\leq \tau))\right].
\end{align*}

## Influence function with censoring and multiple events

In this section, we derive the Influence function for the AUC with more than event and censoring (where the censoring is allowed to depend on the covariates). We now suppose that the censoring distribution depends on the baseline
covariates but continue to assume that the censoring time is
conditionally independent of the event time and event type given the
covariates. To describe the situation with competing risks we introduce a new
random variable \(D\in\{1,2\}\) which indicates the cause (i.e., type
of the event) observed at time \(T\) such that \(D=1\) means that the
event of interest occurred, and \(D=2\) that a competing risk
occurred. As in the survival setting we let \(Q\) denote the joint
probability measure of the uncensored data, \((T,D,X)\sim Q\), and $P$
the joint probability measure of the right censored data
$Z=(\tilde{T},\Delta,X) \sim P$ now with $\Delta=D 1_{\{T \leq C\}}$
taking values in the set \(\{0,1,2\}\). We are interested in the
following definition of the time-dependent discrimination measure for
cause 1:
\begin{align*}
\AUC^1(\tau)&=Q(X_i > X_j \mid T_i\leq \tau, D_i = 1, (T_j > \tau \cup D_j = 2 ))\\
&=\frac{Q(X_i > X_j, T_i\leq \tau, D_i = 1, (T_j > \tau \cup D_j = 2 ))}{Q(T_i\leq \tau, D_i = 1, (T_j > \tau \cup D_j = 2 ))}
\end{align*}
We define a functional $\nu^{1}_{\tau}(Q)$ to represent the numerator:
\begin{align*}
\nu^{1}_{\tau}(Q) &= \iint 1_{\{x > x', t \leqslant \tau, d = 1, ( t^{\prime}>\tau \cup d' = 2)\}} d Q(t, d, x) d Q\left(t^{\prime}, d', \xj\right) \nonumber\\
&= \iint 1_{\{x > x', t \leqslant \tau, ( t^{\prime}>\tau \cup d' = 2)\}} d Q(t, 1, x) d Q\left(t^{\prime}, d', \xj\right)
\psi^{1}_{\tau}(P)  \nonumber\\
&= \iint 1_{\{x > x', t \leqslant \tau,t^{\prime}>\tau\}} + 1_{\{ x > x', t \leqslant \tau, t' \leqslant \tau, d' = 2)\}} d Q(t, 1, x) d Q\left(t^{\prime}, d', \xj\right) \nonumber\\
  &= \iint 1_{\{x > x', t \leqslant \tau,t^{\prime}>\tau\}} dQ(t, 1, x) d Q\left(t^{\prime}, d', \xj\right) \nonumber\\
  &\quad +  \iint 1_{\{ x > x', t \leqslant \tau, t' \leqslant \tau \}} d Q(t, 1, x) d Q\left(t^{\prime}, 2, \xj\right) \nonumber\\
  &= \sum_{\delta^{\prime}=0,1,2} \iint 1_{\{x > x', t \leqslant \tau,  t^{\prime}>\tau\}} \frac{d P(t, 1, x)}{G(t- | x)} \frac{d P\left(t^{\prime}, \delta^{\prime}, \xj\right)}{G\left(\tau | x' \right)} \label{eq:cr-part1-numerator}\\
  &\quad + \iint 1_{\{ x > x', t \leqslant \tau, t' \leqslant \tau \}} \frac{d P(t, 1, x)}{G(t-|x)} \frac{d P(t', 2, x')}{G(t'- | x')}
\end{align*}
We also need the influence function for the censoring as part of our calculations:
\begin{align*}
\kappa_{t,z}(P_{\varepsilon}^i) &= \exp(-\int_0^t \frac{dP_{\varepsilon}(s,0|z)}{P_\varepsilon(\tilde{T} > s|Z=z)}) \\
\partial_{\varepsilon} P_{\varepsilon}(\tilde{T} >s , Z=z) &= \mathbbm{1}_{\{\tilde{T}_i > s, Z_i = z\}}-P(\tilde{T} > s, Z = z) \\
\partial_{\varepsilon} P_{\varepsilon}(\tilde{T} \leq s, \Delta=0, Z=z) &= \mathbbm{1}_{\{\tilde{T}_i \leq s,\Delta_i=0, Z_i = z\}}-P(\tilde{T} \leq s, \Delta=0, Z = z)
\end{align*}
We have when $Z$ is discrete,
\begin{align*}
  &\partial_{\varepsilon} \left[\int_0^t \frac{dP_{\varepsilon}(s,0|z)}{P_\varepsilon(\tilde{T} > s|Z=z)}\right]\\
  &=\int_0^t \frac{\partial_{\varepsilon} dP_{\varepsilon}(s,0,z)P(\tilde{T}_i > s,Z_i=z)}{P(\tilde{T} > s,Z_i=z)^2}
     -\frac{dP(s,0,z)\partial_{\varepsilon} P_\varepsilon(\tilde{T} >s, Z_i=z)}{P(\tilde{T} > s,Z_i=z)^2}\\
  &= \int_0^t \frac{ (d\mathbbm{1}_{\{\tilde{T}_i \leq s,\Delta_i=0, Z_i = z\}}-dP(s,0,z)) P(\tilde{T} > s,Z_i=z)}{P(\tilde{T} > s,Z=z)^2}\\
  &\quad -\frac{dP(s,0,z) (\mathbbm{1}_{\{\tilde{T}_i > s, Z_i = z\}}-P(\tilde{T} > s, Z = z))}{P(\tilde{T} > s,Z=z)^2}\\
  &= \int_0^t \frac{ d\mathbbm{1}_{\{\tilde{T}_i \leq s,\Delta_i=0, Z_i = z\}} P(\tilde{T} > s,Z=z)-dP(s,0,z) \mathbbm{1}_{\{\tilde{T}_i > s, Z_i = z\}}}{P(\tilde{T} > s,Z=z)^2}\\
  &= \frac{\mathbbm{1}_{\{\tilde{T_i} \leq t, \Delta_i = 0, Z_i = z\}}}{P(\tilde{T} > \tilde{T}_i,Z=Z_i)} -\int_0^t \frac{\mathbbm{1}_{\{\tilde{T}_i > s, Z_i = z\}} dP(s,0,z) }{P(\tilde{T} > s,Z=z)^2}\\
  &= \frac{\mathbbm{1}_{\{\tilde{T_i} \leq t, \Delta_i = 0, Z_i = z\}}}{G(\tilde{T_i}|Z_i)S(\tilde{T_i}|Z_i)P(Z=Z_i)} -\int_0^{\tilde{T}_i \wedge t} \frac{ \mathbbm{1}_{\{ Z_i = z\} }dP(s,0,z)}{G(s|Z_i)^2S(s|Z_i)^2 P(Z=Z_i)^2}\\
  &:= f_i(t,z)
\end{align*}
When $Z$ is continuous or mixed, the above has to be modified. Luckily, if we use the trick from before, we can do the calculation again which will mostly be the same, i.e.
$$
 f_i(t,z) = \frac{\mathbbm{1}_{\{\tilde{T_i} \leq t, \Delta_i = 0\}} \delta_{Z_i}(z)}{G(\tilde{T_i}|Z_i)S(\tilde{T_i}|Z_i)} -\int_0^{\tilde{T}_i \wedge t} \frac{ \delta_{Z_i}(z)dP(s,0 | z)}{G(s|Z_i)^2S(s|Z_i)^2}
$$
This just corresponds to setting $\delta_{Z_i}(z) = \frac{{1}_{\{ Z_i = z\}} }{P(Z=Z_i)}$ in the previous calculation.

We have
\begin{align*}
	\partial_{\varepsilon} \left[ \frac{d P_{\varepsilon}\left(t, \delta, x\right)}{\kappa(P_{\varepsilon})\left( s\right)}  \right] &=\frac{d(\delta_{\left\{\tilde{T}_{i}, \Delta_i,X_i\right\}})(t, \delta, x)+dP(t,\delta,x)\left[f_i(s,x)-1\right]}{G(s|x)} 
\end{align*}
So calculations for $\nu_\tau^1 (Q)$ can now be done using the above. This yields that the influence function for the numerator can be written as:
\begin{align}
	\ifnu(\Zi;\tau) &= \frac{1_{\{\tilde{T}_i \leqslant \tau, \Delta_i = 1\}}}{G(\tilde{T_i}- | X_i)}\int  1_{\{X_i > x', t^{\prime}>\tau\}} \frac{dP(t' , x')}{G(\tau | x')} \\
	&+\int 1_{\{t \leqslant \tau\}} \int  1_{\{x > x', t^{\prime}>\tau\}} \frac{dP(t', x')}{G(\tau | x')} \frac{\left[f_i(t-,x)-1\right]dP(t,1,x)}{G(t- | x)}  \\
	&+ \iint 1_{\{x' < x, t \leqslant \tau\}}  \frac{ d P (t, 1, x)}{G(t- | x)} \frac{1_{\{t^{\prime}>\tau\}}\left[f_i(\tau,x')-1\right]dP(t',x')}{G(\tau | x')}  \\
	&+ \left(\frac{1_{ \{ \tilde{T_i} \leq \tau, \Delta_i = 2\}} }{G(\tilde{T_i} - | X_i)} +  \frac{1_{ \{ \tilde{T_i} > \tau \}} }{G(\tau | X_i )}\right) \int 1_{\{X_i<x, t \leqslant \tau\}}  \frac{ d P (t, 1, x)}{G(t- | x)}\\
	&+ \iint 1_{\{x' < x, t \leqslant \tau\}} \frac{ d P (t, 1, x)}{G(t- | x)} 1_{\{t^{\prime} \leqslant \tau\}}(f_i(t'-,x')-1) \frac{dP(t',2,x') }{G(t'- | x')} \\
	&+ \frac{1_{\{\tilde{T}_{i} \leqslant \tau, \Delta_i = 1\}}}{G(\tilde{T}_{i}- | X_i)}\int 1_{\{X_i > x', t^{\prime} \leqslant \tau\}}  \frac{d P\left(t^{\prime},2, \xj\right)}{G(t'- | x')} \\
	&+ \iint 1_{\{x > x', t^{\prime} \leqslant \tau\}}  \frac{d P(dx') \I{\delta'=2}}{G(t'- |x')}  1_{\{t \leqslant \tau\}}\frac{\left[f_i(t-,x)-1\right]dP(t,1,x)}{G(t-| x)}
\end{align}
Next, the denominator is
\begin{align}
	\ifmu(\Zi;\tau) &= \frac{1_{\{\tilde{T}_i \leqslant \tau, \Delta_i = 1\}}}{G(\tilde{T_i}- | X_i)}\int  1_{\{t^{\prime}>\tau\}} \frac{dP(t' , x')}{G(\tau | x')} \\
	&+\int  1_{\{ t^{\prime}>\tau\}} \frac{dP(t', x')}{G(\tau | x')} \int 1_{\{t \leqslant \tau\}}  \frac{\left[f_i(t-,x)-1\right]dP(t,1,x)}{G(t- | x)}  \\
	&+\int 1_{\{t \leqslant \tau\}}  \frac{ d P (t, 1, x)}{G(t- | x)}  \int \frac{1_{\{t^{\prime}>\tau\}}\left[f_i(\tau,x')-1\right]dP(t',x')}{G(\tau | x')} \\
	&+ \left( \frac{1_{ \{ \tilde{T_i} \leq \tau, \Delta_i = 2\}} }{G(\tilde{T_i} - | X_i)}+\frac{1_{ \{ \tilde{T_i} > \tau \}} }{G(\tau | X_i )}\right)\int 1_{\{t \leqslant \tau\}}  \frac{ d P (t, 1, x)}{G(t- | x)}\\
	&+ \int 1_{\{t \leqslant \tau\}} \frac{ d P (t, 1, x)}{G(t- | x)} \int 1_{\{t^{\prime} \leqslant \tau\}} (f_i(t'-,x')-1) \frac{dP(t',2,x') }{G(t'- | x')} \\
	&+ \frac{1_{\{\tilde{T}_{i} \leqslant \tau, \Delta_i = 1\}}}{G(\tilde{T}_{i}- | X_i)}\int 1_{\{t^{\prime} \leqslant \tau\}}  \frac{d P\left(t^{\prime},2, \xj\right)}{G(t'- | x')} \\
	&+ \int 1_{\{t \leqslant \tau\}} (f_i(t-,x)-1) \frac{ d P (t, 1, x)}{G(t- | x)} \int 1_{\{t^{\prime} \leqslant \tau\}}  \frac{dP(t',2,x') }{G(t'- | x')}
\end{align}
The quotient rule now yields that the Gateaux
derivative for the functional
\(\AUC_{\tau}(P)={\nu_{\tau}(Q)}/{\mu_{\tau}(Q)}\) is given by
\begin{equation*}
	\ifauc(Z_i,\tau)=\frac{\ifnu(\Zi;\tau)  \mu_{\tau}(Q) - \nu_{\tau}(Q)  \ifmu(\Zi;\tau)} {\mu_{\tau}(Q)^2}
\end{equation*}
Note that the terms involving 1 actually cancel each other out in the final calculation.

### Some simpler cases 
- Whenever we have survival data instead of competing risk data, the terms corresponding to $\Delta=2$ can be set to zero, i.e. term 5-7 and 12-14. Also, the first part of 4 and 11 is set to zero.
- Whenever we have censoring that does not depend on the covariates, terns 2-3 simplify a bit and are instead written as:

\begin{gather*}
\frac{f_i(\tau)-2}{G(\tau)}\int 1_{\{t \leqslant \tau\}} P(X<x, \tilde{T}>\tau) \frac{1}{G(t-)}dP(t,1,x) \\
+ \frac{1}{G(\tau)} \int 1_{\{t \leqslant \tau\}} P(X<x, \tilde{T}>\tau) \frac{f_i(t-)}{G(t-)}dP(t,1,x) 
\end{gather*}

Similar corrections hold for the denominator. In the code, terms (1-7) are now termed (8-14) and (8-14) are now termed (15-21). Note that $P(X < X_i, \tilde{T} > \tau) = \int 1_{\{t > \tau, x < X_i\}} dP(t,x)$.

### Notes on the case with covariates
- Term (2), (5) and (7) (and also (9), (12), and (14)) may be evaluated by noting the following
$$
\scriptstyle
\int_X \int_0^\tau H(x)f_i(t-,x) \frac{P(dt,k,x)}{G(t-|x)} = H(X_i)\left(\frac{I(\tilde{T}_i \leq \tau, \Delta_i = 0)}{G(\tilde{T}_i|X_i)S(\tilde{T}_i|X_i)}(F_k(\tau|X_i)-F_k(\tilde{T}_i|X_i))-\int_0^{\tilde{T}_i \wedge \tau} \frac{(F_k(\tau|X_i)-F_k(s|X_i))}{G(s|X_i)^2S(s|X_i)^2}P(ds,0|X_i)\right)
$$
where $H$ is an arbitrary function of $x$ (but not $t$!), $k \in \{1,2\}$ and $F_k$ is the subdistribution function for cause $k$.
- For Term (3) (and similarly (10)), we can use that  
$$
\begin{aligned}
\scriptstyle
\int_ X\int H(x')  1_{\{t' > \tau\}} f_i(\tau, x')\frac{P(dt',dx')}{G(\tau | x')}&=\frac{H(X_i)}{G(\tau | X_i)} P(\tilde{T} > \tau | X_i)\left(\frac{I(\tilde{T}_i \leq \tau, \Delta_i = 0)}{G(\tilde{T}_i|X_i)S(\tilde{T}_i|X_i)}-\int_0^{\tilde{T}_i \wedge \tau} \frac{1}{G(s|X_i)^2S(s|X_i)^2}P(ds,0|X_i)\right) \\
&=H(X_i) S(\tau | X_i)\left(\frac{I(\tilde{T}_i \leq \tau, \Delta_i = 0)}{G(\tilde{T}_i|X_i)S(\tilde{T}_i|X_i)}-\int_0^{\tilde{T}_i \wedge \tau} \frac{1}{G(s|X_i)^2S(s|X_i)^2}P(ds,0|X_i)\right) \\
\end{aligned}
$$
where $H$ is again an arbitrary function.

## Estimation 
We estimate as follows: 
\begin{align}
	\ifnu(\Zi;\tau) &= \frac{1_{\{\tilde{T}_i \leqslant \tau, \Delta_i = 1\}}}{\hat{G}(\tilde{T_i}- | X_i)}\int  1_{\{X_i > x', t^{\prime}>\tau\}} \frac{d\emp(t' , x')}{\hat{G}(\tau | x')} \\
	&+\int 1_{\{t \leqslant \tau\}} \int  1_{\{x > x', t^{\prime}>\tau\}} \frac{d\emp(t', x')}{\hat{G}(\tau | x')} \frac{\left[\hat{f}_i(t-,x)-1\right]d\emp(t,1,x)}{\hat{G}(t- | x)}  \\
	&+ \iint 1_{\{x' < x, t \leqslant \tau\}}  \frac{ d \emp (t, 1, x)}{\hat{G}(t- | x)} \frac{1_{\{t^{\prime}>\tau\}}\left[\hat{f}_i(\tau,x')-1\right]d\emp(t',x')}{\hat{G}(\tau | x')}  \\
	&+ \left(\frac{1_{ \{ \tilde{T_i} \leq \tau, \Delta_i = 2\}} }{\hat{G}(\tilde{T_i} - | X_i)} +  \frac{1_{ \{ \tilde{T_i} > \tau \}} }{\hat{G}(\tau | X_i )}\right) \int 1_{\{X_i<x, t \leqslant \tau\}}  \frac{ d \emp (t, 1, x)}{\hat{G}(t- | x)}\\
	&+ \iint 1_{\{x' < x, t \leqslant \tau\}} \frac{ d \emp (t, 1, x)}{\hat{G}(t- | x)} 1_{\{t^{\prime} \leqslant \tau\}}(f_i(t'-,x')-1) \frac{d\emp(t',2,x') }{\hat{G}(t'- | x')} \\
	&+ \frac{1_{\{\tilde{T}_{i} \leqslant \tau, \Delta_i = 1\}}}{\hat{G}(\tilde{T}_{i}- | X_i)}\int 1_{\{X_i > x', t^{\prime} \leqslant \tau\}}  \frac{d \emp\left(t^{\prime},2, \xj\right)}{\hat{G}(t'- | x')} \\
	&+ \iint 1_{\{x > x', t^{\prime} \leqslant \tau\}}  \frac{d \emp\left(t^{\prime},2, \xj\right)}{\hat{G}(t'- |x')}  1_{\{t \leqslant \tau\}}\frac{\left[\hat{f}_i(t-,x)-1\right]d\emp(t,1,x)}{\hat{G}(t-| x)}
\end{align}
Next, the denominator is
\begin{align}
	\ifmu(\Zi;\tau) &= \frac{1_{\{\tilde{T}_i \leqslant \tau, \Delta_i = 1\}}}{\hat{G}(\tilde{T_i}- | X_i)}\int  1_{\{t^{\prime}>\tau\}} \frac{d\emp(t' , x')}{\hat{G}(\tau | x')} \\
	&+\int  1_{\{ t^{\prime}>\tau\}} \frac{d\emp(t', x')}{\hat{G}(\tau | x')} \int 1_{\{t \leqslant \tau\}}  \frac{\left[\hat{f}_i(t-,x)-1\right]d\emp(t,1,x)}{\hat{G}(t- | x)}  \\
	&+\int 1_{\{t \leqslant \tau\}}  \frac{ d \emp (t, 1, x)}{\hat{G}(t- | x)}  \int \frac{1_{\{t^{\prime}>\tau\}}\left[\hat{f}_i(\tau,x')-1\right]d\emp(t',x')}{\hat{G}(\tau | x')} \\
	&+ \left( \frac{1_{ \{ \tilde{T_i} \leq \tau, \Delta_i = 2\}} }{\hat{G}(\tilde{T_i} - | X_i)}+\frac{1_{ \{ \tilde{T_i} > \tau \}} }{\hat{G}(\tau | X_i )}\right)\int 1_{\{t \leqslant \tau\}}  \frac{ d \emp (t, 1, x)}{\hat{G}(t- | x)}\\
	&+ \int 1_{\{t \leqslant \tau\}} \frac{ d \emp (t, 1, x)}{\hat{G}(t- | x)} \int 1_{\{t^{\prime} \leqslant \tau\}} (\hat{f}_i(t'-,x')-1) \frac{d\emp(t',2,x') }{\hat{G}(t'- | x')} \\
	&+ \frac{1_{\{\tilde{T}_{i} \leqslant \tau, \Delta_i = 1\}}}{\hat{G}(\tilde{T}_{i}- | X_i)}\int 1_{\{t^{\prime} \leqslant \tau\}}  \frac{d \emp\left(t^{\prime},2, \xj\right)}{\hat{G}(t'- | x')} \\
	&+ \int 1_{\{t \leqslant \tau\}} (\hat{f}_i(t-,x)-1) \frac{ d \emp (t, 1, x)}{\hat{G}(t- | x)} \int 1_{\{t^{\prime} \leqslant \tau\}}  \frac{d\emp(t',2,x') }{\hat{G}(t'- | x')}
\end{align}

We suggest for estimating this, that the inner part of the integrals are estimated first, because (1) some of the inner integrals appear more than once and (2) for efficiency reasons. Note that, when we have that the censoring is independent of the covariates, we might do some other optimizations as well: We assume that
the survival times are sorted and possibly with ties such that
$\tilde{T}_{1} < \ldots < \tilde{T}_{i} = \ldots = \tilde{T}_{i+k} < \tilde{T}_{i+k+1} < \ldots <
\tilde{T}_n$. We use the following algorithm to preserve memory and the number
of iterations for say $\mu^{(i)} = \int 1_{\{t \leqslant \tau\}} \frac{f_i(t-)}{G(t-)}dP(t,1,x)$. The
idea is to split the sum into two terms:
\begin{gather*}
\frac{1}{n} \sum_{j=1}^n \frac{\hat{f_i}(\tilde{T}_j - )1_{ \{
    \tilde{T}_j \leq \tau, \Delta_j =1 \}}}{\hat{G}(\tilde{T_j}-)} =\\
\frac{1}{n} \left(\sum_{j=2}^{i+k} \frac{g(j) 1_{ \{ \tilde{T}_j \leq
      \tau, \Delta_j =1 \}}}{\hat{G}(\tilde{T_j}-)} +
  h(i)
  \sum_{j=i+k+1}^n \frac{1_{ \{ \tilde{T}_j \leq \tau, \Delta_j =1
      \}}}{\hat{G}(\tilde{T_j}-)} \right)
\end{gather*}

since $\hat{f_i}(\tilde{T}_j - )$ only depends on $i$ for $i+k > j$ and only depends on $j$ for $i+k\leq j$, so these values are calculated a priori. Also the first term will always be zero, since we are looking at the value of the integral before any observed event (hence the sum starts at $j=2$). One can check in the estimation of the Influence Curve for the censoring, which does not depend on the covariates that we need to calculate $2n$ values (i.e. $n$ values for $g(i)$ and $n$ for $h(j)$). This is how we can avoid memory issues. The algorithm is:
\begin{algorithm}[H]
\DontPrintSemicolon
\BlankLine
$t := 1$ \;
$\hat{\mu}_{2}:= \sum_{j=1}^n \frac{1_{ \{ \tilde{T}_j \leq \tau, \Delta_j =1 \}}}{\hat{G}(\tilde{T_j}-)}$ \;
\While{$\tilde{T}_1 = \tilde{T}_t $  and  $t \leq n$ } {
\If{$\tilde{T}_t \leq \tau$ and $\Delta_t = 1$}{
$\hat{\mu}_{2} = \hat{\mu}_{2} - \frac{1}{G(\tilde{T}_t-)}$ \;
}
$t = t + 1$ \;
}
$tieEnd := t-1$ \;
$\hat{\mu}_{1}:=0$ \;
\For{$i = 1$ to $n$}{
    $\hat{\mu}^{(i)}=\frac{1}{n} \left(\hat{\mu}_{1}+ h(i)  \hat{\mu}_{2}  \right) $\;
    \If{$tieEnd \leq i$}{
        $t = i+1$ \;
        \While{$\tilde{T}_1 = \tilde{T}_t $  and  $t \leq n$ } {
                \If{$\tilde{T}_t \leq \tau$ and $\Delta_t = 1$}{
                        $\hat{\mu}_{2} = \hat{\mu}_{2} - \frac{1}{G(\tilde{T}_t-)}$ \;
                        $\hat{\mu}_{1} = \hat{\mu}_{1} + \frac{g(t) 1_{ \{ \tilde{T}_{t} \leq \tau, \Delta_{t} =1 \}}}{\hat{G}(\tilde{T}_{t}-)}$\;
                }
                Let $t = t + 1$ \;
        }
    }
    Let $tieEnd = t-1$ \;
}
return $\hat{\mu}^{(i)}$ for each $i = 1, \ldots, n$ \;
\end{algorithm}

The idea is that but we keep on adding and subtracting the terms with tied values in the event times. Then we do not need to calculate a sum for each $i$.

On the other hand, efficient calculation of some of the estimates can be done for example by sorting the risks $X$ in (1) for the integral there.

## Cross-validation

### Binary case
Our cross-validation algorithm repeatedly splits the dataset \(D_n\) of size $n$
into training and validation datasets as follows. Let \(B\) be a large
integer. For each \(b=1,\ldots,B\) we draw a bootstrap dataset
\(\Db=\{X_{b,1}^*,\ldots,X_{b,m}^*\}\) of size \(m\) with
replacement from the data \(D_n\). For \(i=1,\ldots,n\) let \(N_i^b\) be
the number of times subject \(i\) is included in \(\Db\). In step
\(b\) of the cross-validation algorithm the bootstrap dataset \(\Db\)
is used for training. We apply \(R \) to \(\Db\) to obtain the
prediction model \(\Rbi\). All subjects \(i\) for which \(N_i^b=0\) are
out-of-bag and we let these subjects form the validation dataset of step \(b\). First let us construct the influence function in this case with binary data, $X=(Y,Z)$. In this case, we consider estimation of the functional (i.e. the definition of the AUC in cross-validation)

In this section we extend the ideas from the previous
section and define a \lpo IPCW estimator of AUC.
The AUC can be written as
\begin{align*}
  \text{AUC}(D_m)&=\E_{X_{m+1},X_{m+2}}\Big[\I{\RR(D_m)(Z_{m+1})>\RR(D_m)(Z_{m+2})}\big\vert Y_{m+1} = 1, Y_{m+2} = 0, D_m\Big] \\
  &=\frac{\E_{X_{m+1},X_{m+2}}\Big[\I{\R(Z_{m+1})>\R(Z_{m+2})} \I{Y_{m+1} = 1}\I{Y_{m+2} = 0}\big\vert D_m\Big]}
  {\E_{X_{m+1}}\Big[\I{Y_{m+1} = 1}\Big]\E_{X_{m+2}}\Big[\I{Y_{m+2} = 0}\Big]} 
\end{align*}
With the notation 
\begin{equation*}
  \Theta_{m}(Z_{m+1},Z_{m+2})=\E_{D_m}\big[\I{\R(Z_{m+1})>\R(Z_{m+2})}\big\vert Z_{m+1},Z_{m+2}\big],
\end{equation*}
the expected parameter \(\theta_{m} =\E_{D_n}\big[\text{AUC}(D_n)\big] \) can then be written as 
\begin{align}
  \theta_{m} &=\E_{D_m}\left[\frac{\E_{X_{m+1},X_{m+2}}\Big[\I{\R(Z_{m+1})>\R(Z_{m+2})} \I{Y_{m+1} = 1}\I{Y_{m+2} = 0}\big\vert D_m\Big]}
  {\E_{X_{m+1}}\Big[\I{Y_{m+1} = 1}\Big]\E_{X_{m+2}}\Big[\I{Y_{m+2} = 0}\Big]}\right]\nonumber\\
  &=\frac{\E_{X_{m+1},X_{m+2}}\left[\Theta_{m}(Z_{m+1},Z_{m+2})\I{Y_{m+1} = 1}\I{Y_{m+2} = 0}\right]}
  {\E_{X_{m+1}}\Big[\I{Y_{m+1} = 1}\Big]\E_{X_{m+2}}\Big[\I{Y_{m+2} = 0}\Big]}=\frac{\mathcal{A}_{\tau,m}}{\mathcal{B}_{\tau}}
\end{align}

As before, let \(\Db\) be a bootstrap sample drawn with replacement
from \(D_m\), and let \(\Rbi\) be a prediction modeling algorithm trained in
\(\Db\). The idea of the \lpo estimator is to evaluate the concordance
of predicted risks obtained from \(\Rbi\) for all pairs of subjects
\((i,j)\) for which both subject \(i\) and subject \(j\) is out-of-bag   
\begin{equation*}
  \I{\Rbi(Z_i)>\Rbi(Z_j)}\Ibi\Ibj
\end{equation*}  
The contribution of pair \((i,j)\) to the \lpo estimator is the average
concordance over all bootstrap samples for which both \(i\) and \(j\) are
out-of-bag 
\begin{equation}
\label{eq:lpo}
  \hat{\Theta}^{(1,1)}_{m}(Z_{i},Z_{j})=\frac{\sum_{b=1}^{B}\I{\Rbi(Z_{i})>\Rbi(Z_{j})}\Ibi\Ibj}{\sum_{b=1}^{B}\Ibi\Ibj}
\end{equation}
In the case of no censoring, the \lpo estimate of \(\aucO\) is obtained
by inserting \(\hat{\Theta}^{(1,1)}_{m}\) in
$\theta_m$ and replacing the expectations by empirical means 
\begin{equation*}
  \frac{1}{n^2}\frac{1}{\hat{\mathcal{B}}_\tau}\sum_{i=1}^n\sum_{j=1}^n\hat{\Theta}^{(1,1)}_{m}(Z_{i},Z_{j})\I{Y_i=1}\I{Y_j=0},
\end{equation*}
with
\(\hat{\mathcal{B}}_\tau=n^{-2}\big[\sum_{i=1}^n\I{Y_i=1}\big]\big[\sum_{j=1}^n\I{Y_j=0}\big]\).

### Influence function 

The influence function of the functional
\(\nu_{m}(\P)=\mu_{m}\) in the direction
\(x_k=(t_k,\delta_k,z_k)\) is given by 
\begin{align*}
  \IC_{\nu}(m;x_k)&=\frac{\partial}{\partial\epsilon}\nu_{m}(\P_{\epsilon,k})\Big\vert_{\epsilon=0}\\
  &=\frac{1}{\eta(\P)}\frac{\partial}{\partial\epsilon}\Bigg[\int\int\Bigg(\int\cdots\int\I{\RR(\{x_i\}_{i=1}^m)(z_{m+1})>\RR(\{x_i\}_{i=1}^m)(z_{m+2})}\prod_{i=1}^m\P_{\epsilon,k}(\D x_i)\Bigg)\\
  &\hspace{0.7cm} \I{y_{m+1}=1,y_{m+2}=0}\P_{\epsilon,k}(\D x_{m+1})\P_{\epsilon,k}(\D x_{m+2})\Bigg]\Bigg\vert_{\epsilon=0}
  -\frac{\partial}{\partial\epsilon}\frac{\eta(\P_{\epsilon,k})}{\eta(\P)}\nu_{m}(\P)\Big\vert_{\epsilon=0}
\end{align*}
It follows that
\begin{align*}
  \IC_{\nu}(m;x_k)&=\frac{1}{\eta(\P)}\int\Theta_{m}(z_k,z_{m+2})\I{y_{k}=1,y_{m+2}=0}\P(\D x_{m+2})-\nu_{m}(\P) \\
  &+\frac{1}{\eta(\P)}\int\Theta_{m}(z_{m+1},z_k) \I{y_{m+1}=1,y_{k}=0}\P(\D x_{m+1})-\nu_{m}(\P)\\
  &+\frac{1}{\eta(\P)}\int\int\frac{\partial}{\partial\epsilon}\int\cdots\int\I{\RR(\{x_i\}_{i=1}^m)(z_{m+1})>\RR(\{x_i\}_{i=1}^m)(z_{m+2})}\prod_{i=1}^m\P_{\epsilon,k}(\D x_i)\\
  &\hspace{0.3cm}\I{y_{m+1}=1,y_{m+2}=0} \P(\D x_{m+1})\P(\D x_{m+2})\Big\vert_{\epsilon=0}\\
  &-\frac{\partial}{\partial\epsilon}\frac{\nu_{m}(\P)}{\eta(\P)}\eta(\P_{\epsilon,k})\Big\vert_{\epsilon=0}
\end{align*}
Hence, after some calculations, 
\begin{align*}
  &\IC_{\nu}(m;x_k)=\frac{1}{\eta(\P)}\Big[\int\Theta_{m}(z_{m+1},z_k)\I{y_{k}=1,y_{m+2}=0}\P(\D x_{m+1})\\
  &\hspace{3cm}+\int\Theta_{m}(z_k,z_{m+2})\I{y_{m+1}=1,y_{k}=0}\P(\D x_{m+2})\Big]-m\, \nu_{m}(\P)\\
  &+\frac{1}{\eta(P)}\int\int\sum_{j=1}^m \int\cdots\int\I{\RR(\{x_i\}_{i=1}^m)(z_{m+1})>\RR(\{x_i\}_{i=1}^m)(z_{m+2})}\delta_{x_k}(x_j)\prod_{i\neq j}\P(\D x_i)\\
  &\hspace{0.4cm}\I{y_{m+1}=1,y_{m+2}=0}\P(\D x_{m+1})\P(\D x_{m+2})\\
  &-\frac{\nu_{m}(\P)}{\eta(\P)}\Big[\I{y_k=1}\Big]
  \Big[\int \I{y_{m+2}=0}\P(\D x_{m+2})\Big]\\
  &-\frac{\nu_{n}(\P)}{\eta(\P)}\Big[\int \I{y_{m+1}=1}\P(\D x_{m+1})\Big]
  \Big[\I{y_k=0}\Big]
\end{align*}

## Survival and Competing risk cases (and more generally)
We note that we may actually use our results from the test-train section on any functional, $\phi(D_m)_\tau$ defined in the test-train situation. Then the influence function of the function  $\Phi_\tau := \mathbb{E}_{D_m} [\phi(D_m)_\tau]$ from the test-train situation as follows by finding the Gateaux derivative for observation $i$

$$
\int \cdots \int \text{IC}_{\phi(D_m)_\tau}^i P(dx_1) \cdots P(dx_m) + \sum_{j=1}^m  \int \cdots \int \phi(D_m)_\tau \delta_{x_j}(x_k) \prod_{i \neq j} P(dx_i) - m \Phi_\tau 
$$

The idea is now to interchange the order of integration (both terms), so that we may use leave-one-out bootstrap estimates. Indeed, for the most general case (competing risk case), we get that 
\begin{align*}
\frac{\ifnu(\Zi;\tau,m)\mu_\tau(P) - \nu^{1}_{\tau,m}(P) \ifmu(\Zi;\tau)}{\mu_\tau(P)^2 }+ \frac{\nu^{2}_{\tau, m} }{\mu_\tau (P)} - m \Phi_\tau 
\end{align*}
where 
\begin{align*}
\nu^{1}_{\tau, m}(P)&= \iint \Theta_m(x,x' )1_{\{t \leqslant \tau,  t^{\prime}>\tau\}} \frac{P(dx) \I{\delta=1}}{G(t- | z)} \frac{P(dx')}{G\left(\tau | z' \right)} \\ 
&\quad + \iint  \Theta_m(x,x' ) 1_{\{t \leqslant \tau, t' \leqslant \tau \}} \frac{P(dx) \I{\delta=1}}{G(t-|z)} \frac{P(dx')\I{\delta'=2}}{G(t'- | z')}
\end{align*}
and similarly defined 
\begin{align*}
\nu^{2}_{\tau, m}&= \iint \sum_{j=1}^m \Theta_m(x,x' )^{(j,k)} 1_{\{t \leqslant \tau,  t^{\prime}>\tau\}} \frac{P(dx) \I{\delta=1}}{G(t- | z)} \frac{P(dx')}{G\left(\tau | z' \right)} \\ 
&\quad + \iint  \sum_{j=1}^m \Theta_m(x,x' )^{(j,k)} 1_{\{t \leqslant \tau, t' \leqslant \tau \}} \frac{P(dx) \I{\delta=1}}{G(t-|z)} \frac{P(dx')\I{\delta'=2}}{G(t'- | z')}
\end{align*}
where 
$$
\Theta_m(x,x' )^{(j,k)} = \int \dots \int \I{R(D_m)(z) > R(D_m)(z')} \delta_{x_j}(x_k) \prod_{i \neq j} P(dx_i)
$$
Note that $\mu_{\tau}(P)$ is defined precisely as before (and hence also $\ifmu$ is the same), but we must redefine, $\ifnu$
\begin{align*}
	\ifnu(\Zi;\tau,m) &= \frac{1_{\{\tilde{T}_i \leqslant \tau, \Delta_i = 1\}}}{G(\tilde{T_i}- | Z_i)}\int  \Theta_m(X_i,x') 1_{\{t^{\prime}>\tau\}} \frac{P(dx')}{G(\tau | z')} \\
	&+\int 1_{\{t \leqslant \tau\}} \int  \Theta_m(x,x') 1_{\{t^{\prime}>\tau\}} \frac{P(dx')}{G(\tau | z')} \frac{\left[f_i(t-,z   )-1\right] P(dx) \I{\delta=1}} {G(t- | z)}  \\
	&+ \iint  \Theta_m(x,x')  1_{\{t \leqslant \tau\}}  \frac{P(dx) \I{\delta=1}}{G(t- | z)} \frac{1_{\{t^{\prime}>\tau\}}\left[f_i(\tau,z')-1\right]P(dx')}{G(\tau | z')}  \\
	&+ \left(\frac{1_{ \{ \tilde{T_i} \leq \tau, \Delta_i = 2\}} }{G(\tilde{T_i} - | Z_i)} +  \frac{1_{ \{ \tilde{T_i} > \tau \}} }{G(\tau | Z_i )}\right) \int \Theta_m(x,X_i )1_{\{t \leqslant \tau\}}  \frac{P(dx) \I{\delta=1}}{G(t- | x)}\\
	&+ \iint \Theta_m(x,x') 1_{\{t \leqslant \tau\}} \frac{P(dx) \I{\delta=1}}{G(t- | z)} 1_{\{t^{\prime} \leqslant \tau\}}(f_i(t'-,z')-1) \frac{P(dx') \I{\delta'=2}}{G(t'- | z')} \\
	&+ \frac{1_{\{\tilde{T}_{i} \leqslant \tau, \Delta_i = 1\}}}{G(\tilde{T}_{i}- | Z_i)}\int \Theta_m(X_i,x') 1_{\{t^{\prime} \leqslant \tau\}}  \frac{P (dx') \I{\delta'=2}}{G(t'- | z')} \\
	&+ \iint \Theta_m(x,x') 1_{\{t^{\prime} \leqslant \tau\}}  \frac{P(dx')\I{\delta=2}}{G(t'- |z')}  1_{\{t \leqslant \tau\}}\frac{\left[f_i(t-,z)-1\right]P(dx)\I{\delta=1}}{G(t-| z)}
\end{align*}
The functional can also be found as $\frac{\nu^{1}_{\tau,m}(P)}{\mu_\tau (P)}$, and the functional and the terms in its influence function can be estimated in mostly the same way as Brier. Most likely, we don't need the ones here as well.